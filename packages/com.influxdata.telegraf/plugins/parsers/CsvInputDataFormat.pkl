//===----------------------------------------------------------------------===//
// Copyright Â© 2024 Apple Inc. and the Pkl project authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//===----------------------------------------------------------------------===//
/// The `csv` parser creates metrics from a document containing comma separated values.
@ModuleInfo { minPklVersion = "0.25.0" }
open module com.influxdata.telegraf.plugins.parsers.CsvInputDataFormat

extends "InputDataFormat.pkl"

files: Listing<String>

data_format: "csv"

/// Indicates how many rows to treat as a header.
///
/// By default, the parser assumes there is no header and will parse the first row as data.
/// If set to anything more than 1, column names will be concatenated with the name listed in the next header row.
/// If [csv_column_names] is specified, the column names in header will be overridden.
csv_header_row_count: Int(isPositive)?

/// For assigning custom names to columns.
///
/// If this is specified, all columns should have a name.
/// Unnamed columns will be ignored by the parser.
/// If [csv_header_row_count] is set to 0, this config must be used.
csv_column_names: Listing<String>?

/// For assigning explicit data types to columns.
///
/// Specify types in order by column (e.g., `csv_column_types { "string"; "int"; "float" }`).
/// If this is not specified, type conversion will be done on the types above.
csv_column_types: Listing<"int"|"float"|"bool"|"string">?

/// Indicates the number of rows to skip before looking for header information.
csv_skip_rows: Int(isPositive)?

/// Indicates the number of columns to skip before looking for data to parse.
///
/// These columns will be skipped in the header as well.
csv_skip_columns: Int(isPositive)?

/// The separator between csv fields.
///
/// Default: `","`
csv_delimiter: String?

/// The character reserved for marking a row as a comment row.
///
/// Commented rows are skipped and not parsed.
csv_comment: String?

/// If set to true, the parser will remove leading whitespace from fields.
///
/// Default: `false`
csv_trim_space: Boolean?

/// Columns listed here will be added as tags.
///
/// Any other columns will be added as fields.
csv_tag_columns: Listing<String>?

/// The column to extract the name of the metric from.
///
/// Will not be included as field in metric.
csv_measurement_column: String?

/// The column to extract time information for the metric.
///
/// [csv_timestamp_format] must be specified if this is used.
/// Will not be included as field in metric.
csv_timestamp_column: String?

/// The format of time data extracted from [csv_timestamp_column].
///
/// This must be specified if [csv_timestamp_column] is specified.
csv_timestamp_format: String?

/// The timezone of time data extracted from [csv_timestamp_column]
/// in case there is no timezone information.
///
/// It follows the IANA Time Zone database.
csv_timezone: String?

/// Indicates values to skip, such as an empty string value `""`.
///
/// The field will be skipped entirely where it matches any values inserted here.
csv_skip_values: Listing<String>?
