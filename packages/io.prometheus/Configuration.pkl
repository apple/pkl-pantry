//===----------------------------------------------------------------------===//
// Copyright Â© 2024 Apple Inc. and the Pkl project authors. All rights reserved.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//===----------------------------------------------------------------------===//
/// Prometheus is configured via command-line flags and a configuration file.
///
/// While the command-line flags configure immutable system parameters
/// (such as storage locations, amount of data to keep on disk and in memory, etc.),
/// the configuration file defines everything related to scraping
/// [jobs and their instances](https://prometheus.io/docs/concepts/jobs_instances/),
/// as well as which
/// [rule files to load](https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/#configuring-rules).
///
/// To view all available command-line flags, run `./prometheus -h`.
///
/// Prometheus can reload its configuration at runtime.
/// If the new configuration is not well-formed, the changes will not be applied.
/// A configuration reload is triggered by sending a `SIGHUP` to the Prometheus process
/// or sending a HTTP POST request to the `/-/reload` endpoint
/// (when the `--web.enable-lifecycle` flag is enabled).
/// This will also reload any configured rule files.
///
/// More details: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#configuration-file>
@ModuleInfo { minPklVersion = "0.25.0" }
open module io.prometheus.Configuration

extends "PrometheusObject.pkl"

/// The global configuration specifies parameters that are valid in all other configuration contexts.
///
/// They also serve as defaults for other configuration sections.
global: GlobalConfig?

/// Alerting specifies settings related to the Alertmanager.
alerting: AlertingConfig?

/// A list of scrape configurations.
scrape_configs: Listing<ScrapeConfig>?

/// Settings related to the remote write feature.
remote_write: Listing<RemoteWriteConfig>?

/// Settings related to the remote read feature.
remote_read: Listing<RemoteReadConfig>?

/// A list of globs. Rules and alerts are read from all matching files.
rule_files: Listing<String>?

class GlobalConfig {
  /// How frequently to evaluate rules
  ///
  /// Default: `1.min`
  evaluation_interval: Duration?

  /// The labels to add to any time series or alerts when communicating
  /// with external systems (federation, remote storage, Alertmanager).
  external_labels: Labels?

  /// File to which PromQL queries are logged.
  ///
  /// Reloading the configuration will reopen the file.
  query_log_file: String?

  /// How long until a scrape request times out.
  ///
  /// Default if omitted: `10.s`
  scrape_timeout: Duration?

  /// How frequently to evaluate rules.
  ///
  /// Default if omitted: `1.min`
  scrape_interval: Duration?
}

/// A set of targets and parameters describing how to scrape them.
///
/// In the general case, one scrape configuration specifies a single job.
/// In advanced configurations, this may change.
///
/// Targets may be statically configured via [static_configs]
/// or dynamically discovered using one of the supported service-discovery mechanisms.
///
/// Additionally, [relabel_configs] allow advanced modifications to any target and its labels before scraping.
///
/// More details: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config>
open class ScrapeConfig {
  /// The job name assigned to scraped metrics by default.
  job_name: String

  /// How frequently to scrape targets from this job.
  ///
  /// Default if omitted: [GlobalConfig.scrape_interval]
  scrape_interval: Duration?

  /// Per-scrape timeout when scraping this job.
  ///
  /// Default if omitted: [GlobalConfig.scrape_timeout]
  scrape_timeout: Duration?

  /// The HTTP resource path on which to fetch metrics from targets.
  ///
  /// Default if omitted: `"/metrics"`
  metrics_path: String?

  /// Controls how Prometheus handles conflicts between labels that are
  /// already present in scraped data and labels that Prometheus would attach
  /// server-side ("job" and "instance" labels, manually configured target
  /// labels, and labels generated by service discovery implementations).
  ///
  /// If [true], label conflicts are resolved by keeping label
  /// values from the scraped data and ignoring the conflicting server-side labels.
  ///
  /// If [false], label conflicts are resolved by renaming conflicting labels
  /// in the scraped data to "exported_<original-label>" (for example "exported_instance", "exported_job")
  /// and then attaching server-side labels.
  ///
  /// Setting [honor_labels] to [true] is useful for use cases such as federation
  /// and scraping the Pushgateway, where all labels specified in the target should be preserved.
  ///
  /// Note that any globally configured [GlobalConfig.external_labels] are unaffected by this setting.
  /// In communication with external systems, they are always applied only
  /// when a time series does not have a given label yet and are ignored otherwise.
  ///
  /// Default if omitted: [false]
  honor_labels: Boolean?

  /// Controls whether Prometheus respects the timestamps present in scraped data.
  ///
  /// If [true], the timestamps of the metrics exposed by the target will be used.
  ///
  /// If [false], the timestamps of the metrics exposed by the target will be ignored.
  ///
  /// Default if omitted: [true]
  honor_timestamps: Boolean?

  /// Configures the protocol scheme used for requests.
  ///
  /// Default if omitted: `"http"`
  scheme: Scheme?

  /// Optional HTTP URL parameters.
  params: Mapping<String, Listing<String>>?

  /// Sets the `Authorization` header on every scrape request
  /// with the configured username and password.
  basic_auth: BasicAuth?

  /// Sets the `Authorization` header on every scrape request with the configured bearer token.
  ///
  /// Mutually exclusive with [bearer_token_file].
  bearer_token: String(bearer_token_file == null)?

  /// Sets the `Authorization` header on every scrape request
  /// with the bearer token read from the configured file.
  ///
  /// Mutually exclusive with [bearer_token].
  bearer_token_file: String?

  /// Configures the scrape request's TLS settings.
  tls_config: TLSConfig?

  /// Optional proxy URL.
  proxy_url: String?

  /// List of Kubernetes service discovery configurations.
  kubernetes_sd_configs: Listing<KubernetesSdConfig>?

  /// List of file service discovery configurations.
  file_sd_configs: Listing<FileSdConfig>?

  /// List of DNS-based service discovery configurations.
  dns_sd_configs: Listing<DnsSdConfig>?

  /// List of labeled statically configured targets for this job.
  static_configs: Listing<StaticConfig>?

  /// List of target relabel configurations.
  relabel_configs: Listing<RelabelConfig>?

  /// List of metric relabel configurations.
  metric_relabel_configs: Listing<RelabelConfig>?

  /// Per-scrape limit on number of scraped samples that will be accepted.
  ///
  /// If more than this number of samples are present after metric relabeling,
  /// the entire scrape will be treated as failed.
  /// `0` means no limit.
  ///
  /// Default if omitted: `0`
  sample_limit: UInt?

  /// Per-scrape config limit on number of unique targets that will be accepted.
  ///
  /// If more than this number of targets are present after target relabeling,
  /// Prometheus will mark the targets as failed without scraping them.
  /// `0` means no limit.
  ///
  /// This is an experimental feature, this behaviour could change in the future.
  ///
  /// Default if omitted: `0`
  target_limit: UInt?
}

/// Allow retrieving scrape targets from Kubernetes' REST API
/// and always staying synchronized with the cluster state.
///
/// One of the following role types can be configured to discover targets:
///
/// More details: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#kubernetes_sd_config>
class KubernetesSdConfig {
  /// The Kubernetes role of entities that should be discovered.
  role: *"pod"|"service"|"node"|"endpoints"|"ingress"

  /// Optional namespace discovery.
  ///
  /// Default if omitted: all namespaces are used
  namespaces: NamespaceSpec?

  /// The API server addresses.
  ///
  /// If left empty, Prometheus is assumed to run inside of the cluster
  /// and will discover API servers automatically and use the pod's CA certificate
  /// and bearer token file at /var/run/secrets/kubernetes.io/serviceaccount/.
  api_server: String?

  /// Optional label and field selectors to limit the discovery process to a subset of available resources.
  ///
  /// See <https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/>
  /// and <https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/>
  /// to learn more about the possible filters that can be used.
  /// Endpoints role supports pod, service and endpoints selectors,
  /// other roles only support selectors matching the role itself
  /// (e.g. node role can only contain node selectors).
  ///
  /// Note: When making decision about using field/label selector,
  /// make sure that this is the best approach -
  /// it will prevent Prometheus from reusing single list/watch for all scrape configs.
  /// This might result in a bigger load on the Kubernetes API,
  /// because per each selector combination there will be additional LIST/WATCH.
  /// On the other hand, if you just want to monitor small subset of pods in large cluster,
  /// it's recommended to use selectors.
  /// If selectors should be used or not depends on the particular situation.
  selectors: Listing<KubernetesSdConfigSelector>?
}

class KubernetesSdConfigSelector {
  role: *"pod"|"service"|"node"|"endpoints"|"ingress"

  /// A `key=value` pair describing a Kubernetes resource label.
  ///.
  /// See <https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/>.
  label: String?

  /// A `key=value` pair describing a Kubernetes field selector.
  ///
  /// See <https://kubernetes.io/docs/concepts/overview/working-with-objects/field-selectors/>.
  field: String?
}

/// File-based service discovery provides a more generic way to configure static targets and
/// serves as an interface to plug in custom service discovery mechanisms.
///
/// It reads a set of files containing a list of zero or more `<static_config>`s. Changes to all
/// defined files are detected via disk watches and applied immediately. Files may be provided in
/// YAML or JSON format. Only changes resulting in well-formed target groups are applied.
class FileSdConfig {
  /// Patterns for files from which target groups are extracted.
  ///
  /// Files may end with `.json`, `.yaml` or `.yml`. The last path segment may contain a single `*`
  /// that matches any character sequence, e.g. `my/path/tg_*.json`.
  files: Listing<String(endsWith(Regex(#"\.(json|ya?ml)"#)))>

  /// Refresh interval to re-read the files.
  ///
  /// Defaults to `5.m`.
  refresh_interval: Duration?
}

/// DNS-based service discovery configuration allows specifying a set of DNS domain names which
/// are periodically queried to discover a list of targets.
///
/// <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#dns_sd_config>
class DnsSdConfig {
  /// A list of DNS domain names to be queried.
  names: Listing<String>

  /// The type of DNS query to perform. One of SRV, A, AAAA, MX or NS.
  ///
  /// Default if unspecified: `"SRV"`
  type: ("SRV"|"A"|"AAAA"|"MX"|"NS")?

  /// The port number used if the query type is not SRV.
  port: UInt16?((type != null && type != "SRV").implies(this != null))

  /// The time after which the provided names are refreshed.
  ///
  /// Default if unspecified: `30.s`
  refresh_internal: Duration?
}

class NamespaceSpec {
  names: Listing<String>
}

/// Relabeling is a powerful tool to dynamically rewrite the label set of a target before it gets scraped.
///
/// Multiple relabeling steps can be configured per scrape configuration.
/// They are applied to the label set of each target in order of their appearance in the configuration file.
///
/// Initially, aside from the configured per-target labels,
/// a target's `job` label is set to the `job_name` value of the respective scrape configuration.
/// The `__address__` label is set to the `<host>:<port>` address of the target.
/// After relabeling, the `instance` label is set to the value of `__address__`
/// by default if it was not set during relabeling.
/// The `__scheme__` and `__metrics_path__` labels
/// are set to the scheme and metrics path of the target respectively.
/// The `__param_<name>` label is set to the value of the first passed URL parameter called `<name>`.
///
/// Additional labels prefixed with `__meta_` may be available during the relabeling phase.
/// They are set by the service discovery mechanism that provided the target and vary between mechanisms.
///
/// Labels starting with `__` will be removed from the label set after target relabeling is completed.
///
/// If a relabeling step needs to store a label value only temporarily
/// (as the input to a subsequent relabeling step), use the `__tmp` label name prefix.
/// This prefix is guaranteed to never be used by Prometheus itself.
///
/// More details: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#relabel_config>
class RelabelConfig {
  /// The source labels select values from existing labels.
  ///
  /// Their content is concatenated using the configured separator
  /// and matched against the configured regular expression for the replace, keep, and drop actions.
  source_labels: Listing<String>?

  /// Separator placed between concatenated source label values.
  separator: String?

  /// Action to perform based on regex matching.
  action: RelabelAction?

  /// Regular expression against which the extracted value is matched.
  @SourceCode { language = "RegExp" }
  regex: String(isRegex)?

  /// Label to which the resulting value is written in a replace action.
  ///
  /// Mandatory for replace actions.
  /// Regex capture groups are available.
  target_label: String?

  /// Modulus to take of the hash of the source label values.
  modulus: Int?

  /// Replacement value against which a regex replace is performed if the regular expression matches.
  ///
  /// Regex capture groups are available.
  replacement: String?
}

/// Which relabel action to perform.
///
/// * `"replace"`: Match `regex` against the concatenated `source_labels`.
///   Then, set `target_label` to `replacement`, with match group references
///   (`${1}`, `${2}`, ...) in `replacement` substituted by their value.
///   If `regex` does not match, no replacement takes place.
/// * `"keep"`: Drop targets for which `regex` does not match the concatenated `source_labels`.
/// * `"drop"`: Drop targets for which `regex` matches the concatenated `source_labels`.
/// * `"hashmod"`: Set `target_label` to the `modulus` of a hash of the concatenated `source_labels`.
/// * `"labelmap"`: Match `regex` against all label names.
///   Then copy the values of the matching labels to label names given by `replacement`
///   with match group references (`${1}`, `${2}`, ...) in `replacement` substituted by their value.
/// * `"labeldrop"`: Match `regex` against all label names.
///   Any label that matches will be removed from the set of labels.
/// * `"labelkeep"`: Match `regex` against all label names.
typealias RelabelAction = *"replace"|"keep"|"drop"|"hashmod"|"labelmap"|"labeldrop"|"labelkeep"

/// Allows specifying a list of targets and a common label set for them.
///
/// It is the canonical way to specify static targets in a scrape configuration.
///
/// More details: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#static_config>
class StaticConfig {
  /// The targets specified by the static config.
  targets: Listing<String>?

  /// Labels assigned to all metrics scraped from the targets.
  labels: Labels?
}

/// [write_relabel_configs] is relabeling applied to samples
/// before sending them to the remote endpoint.
///
/// Write relabeling is applied after external labels.
/// This could be used to limit which samples are sent.
///
/// There is a small demo (/documentation/examples/remote_storage) of how to use this functionality.
///
/// More detail: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#remote_write>
class RemoteWriteConfig {
  /// The URL of the endpoint to send samples to.
  url: String

  /// Timeout for requests to the remote write endpoint.
  ///
  /// Default if omitted: `30.s`
  remote_timeout: Duration?

  /// Custom HTTP headers to be sent along with each remote write request.
  ///
  /// Be aware that headers that are set by Prometheus itself can't be overwritten.
  headers: Labels?

  /// List of remote write relabel configurations.
  write_relabel_configs: Listing<RelabelConfig>?

  /// Name of the remote write config, which if specified must be unique among remote write configs.
  ///
  /// The name will be used in metrics and logging in place of a generated value
  /// to help users distinguish between remote write configs.
  name: String?

  /// Sets the `Authorization` header on every remote write request
  /// with the configured username and password.
  basic_auth: BasicAuth?

  /// Sets the `Authorization` header on every remote write request with the configured bearer token.
  ///
  /// Mutually exclusive with [bearer_token_file].
  bearer_token: String(bearer_token_file == null)?

  /// Sets the `Authorization` header on every remote write request
  /// with the bearer token read from the configured file.
  ///
  /// Mutually exclusive with [bearer_token].
  bearer_token_file: String?

  /// Configures the remote write request's TLS settings.
  tls_config: TLSConfig?

  /// Optional proxy URL.
  proxy_url: String?

  /// Configures the queue used to write to remote storage.
  queue_config: QueueConfig?

  /// Configures the sending of series metadata to remote storage.
  ///
  /// Metadata configuration is subject to change at any point or be removed in future releases.
  metadata_config: MetadataConfig?

  /// Configures AWS's Signature Verification 4 signing process.
  ///
  /// Signature Verification signs requests.
  /// To use the default credentials from the AWS SDK, use `sigv4 {}`.
  sigv4: Sigv4Config((basic_auth ?? bearer_token) == null)?
}

class MetadataConfig {
  /// Whether metric metadata is sent to remote storage or not.
  ///
  /// Default if omitted: [true]
  send: Boolean?

  /// How frequently metric metadata is sent to remote storage.
  ///
  /// Default if omitted: `1.min`
  send_interval: Duration?
}

class QueueConfig {
  /// Number of samples to buffer per shard before we block reading of more samples from the WAL.
  ///
  /// It is recommended to have enough capacity in each shard to buffer several requests
  /// to keep throughput up while processing occasional slow remote requests.
  ///
  /// Default if omitted: `2500`
  capacity: Int?

  /// Maximum number of shards, i.e. amount of concurrency.
  ///
  /// Default if omitted: `200`
  max_shards: Int?

  /// Minimum number of shards, i.e. amount of concurrency.
  ///
  /// Default if omitted: `1`
  min_shards: Int?

  /// Maximum number of samples per send.
  ///
  /// Default if omitted: `500`
  max_samples_per_send: Int?

  /// Maximum time a sample will wait in buffer.
  ///
  /// Default if omitted: `5.s`
  batch_send_deadline: Duration?

  /// Initial retry delay. Gets doubled for every retry.
  ///
  /// Default if omitted: `30.ms`
  min_backoff: Duration?

  /// Maximum retry delay.
  ///
  /// Default if omitted: `100.ms`
  max_backoff: Duration?
}

class AlertingConfig {
  alertmanagers: Listing<AlertManagerConfig>?
}

/// Specifies Alertmanager instances the Prometheus server sends alerts to.
///
/// Also provides parameters to configure how to communicate with these Alertmanagers.
///
/// Alertmanagers may be statically configured via the [static_configs] parameter
/// or dynamically discovered using one of the supported service-discovery mechanisms.
///
/// Additionally, [relabel_configs] allow selecting Alertmanagers
/// from discovered entities and provide advanced modifications to the used API path,
/// which is exposed through the `__alerts_path__` label.
///
/// More details: <https://prometheus.io/docs/prometheus/latest/configuration/configuration/#alertmanager_config>
class AlertManagerConfig {
  /// The api version of Alertmanager.
  ///
  /// Default if omitted: `"v1"`
  api_version: String?

  /// Prefix for the HTTP path alerts are pushed to.
  path_prefix: String?

  /// Configures the protocol scheme used for requests.
  scheme: Scheme?

  /// Per-target Alertmanager timeout when pushing alerts.
  ///
  /// Default if omitted: `10.s`
  timeout: Duration?

  /// Sets the `Authorization` header on every request with the configured username and password.
  basic_auth: BasicAuth?

  /// Sets the `Authorization` header on every request with the configured bearer token.
  ///
  /// Mutually exclusive with [bearer_token_file].
  bearer_token: String(bearer_token_file == null)?

  /// Sets the `Authorization` header on every request with the bearer token read from the configured file.
  ///
  /// Mutually exclusive with [bearer_token].
  bearer_token_file: String?

  /// Configures the scrape request's TLS settings.
  tls_config: TLSConfig?

  /// Optional proxy URL.
  proxy_url: String?

  /// List of Kubernetes service discovery configurations.
  kubernetes_sd_configs: Listing<KubernetesSdConfig>?

  /// List of labeled statically configured Alertmanagers.
  static_configs: Listing<StaticConfig>?

  /// List of Alertmanager relabel configurations.
  relabel_configs: Listing<RelabelConfig>?
}

/// Allows configuring TLS connections.
class TLSConfig {
  /// CA certificate to validate API server certificate with.
  ca_file: String?

  /// Certificate file for client cert authentication to the server.
  cert_file: String?

  /// Key file for client cert authentication to the server.
  key_file: String?

  /// ServerName extension to indicate the name of the server.
  ///
  /// <https://tools.ietf.org/html/rfc4366#section-3.1>
  server_name: String?

  /// Disable validation of the server certificate.
  insecure_skip_verify: Boolean?
}

class RemoteReadConfig {
  /// The URL of the endpoint to query from.
  url: String

  /// Name of the remote read config, which if specified must be unique among remote read configs.
  ///
  /// The name will be used in metrics and logging in place of a generated value
  /// to help users distinguish between remote read configs.
  name: String?

  /// An optional list of equality matchers which have to be present
  /// in a selector to query the remote read endpoint.
  required_matchers: Labels?

  /// Timeout for requests to the remote read endpoint.
  ///
  /// Default if omitted: `1.min`
  remote_timeout: Duration?

  /// Whether reads should be made for queries for time ranges
  /// that the local storage should have complete data for.
  read_recent: Boolean?

  /// Sets the `Authorization` header on every remote read request
  /// with the configured username and password.
  basic_auth: BasicAuth?

  /// Sets the `Authorization` header on every remote read request
  /// witb the configured bearer token.
  ///
  /// Mutually exclusive with [bearer_token_file].
  bearer_token: String(bearer_token_file == null)?

  /// Sets the `Authorization` header on every remote read request
  /// with the bearer token read from the configured file.
  ///
  /// Mutually exclusive with [bearer_token].
  bearer_token_file: String?

  /// Configures the remote read request's TLS settings.
  tls_config: TLSConfig?

  /// Optional proxy URL.
  proxy_url: String?
}

class BasicAuth {
  username: String?

  /// Mutually exclusive with [password_file].
  password: String(password_file == null)?

  /// Mutually exclusive with [password].
  password_file: String?
}

class Sigv4Config {
  /// The AWS region (if blank, the region from the default credentials chain is used).
  region: String?

  /// The AWS API keys.
  access_key: String?
  secret_key: String?

  /// AWS profile used to authenticate.
  profile: String?

  /// AWS Role ARN, an alternative to using AWS API Keys.
  role_arn: String?
}
